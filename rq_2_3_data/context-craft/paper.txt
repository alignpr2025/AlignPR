For a given functional description (ğ‘“ ğ‘‘), example retrieval is to retrieve a few closely related exam-
ples from a predefined corpus. The key of the retrieval is the measurement of contextual similarity
between the query (i.e., ğ‘“ ğ‘‘) and the examples in the corpus. Notably, every example ğ‘’ in the corpus
comprises two parts: The functional description of a method (denoted as ğ·(ğ‘’)) and the name of the
method (denoted as ğ‘ (ğ‘’)). While computing the similarity between ğ‘“ ğ‘‘ and ğ‘’, we only compare
ğ·(ğ‘’) against ğ‘“ ğ‘‘ because both are functional descriptions:
ğ‘†(ğ‘“ ğ‘‘, ğ‘’) = ğ‘‡ ğ‘†(ğ‘“ ğ‘‘, ğ·(ğ‘’)) (1)
where ğ‘†(ğ‘“ ğ‘‘, ğ‘’) is the similarity between the input query ğ‘“ ğ‘‘ and the example ğ‘’ from the corpus.
ğ‘‡ ğ‘†(ğ‘“ ğ‘‘, ğ·(ğ‘’)) is the text similarity between two functional descriptions ğ‘“ ğ‘‘ and ğ·(ğ‘’). The Text
similarity is computed using cosine similarity between vector representations of ğ‘“ ğ‘‘ and ğ·(ğ‘’) as
follows:
ğ‘‡ ğ‘†(ğ‘“ ğ‘‘, ğ·(ğ‘’)) = cos(ğ‘£ ğ‘’ğ‘(ğ‘“ ğ‘‘), ğ‘£ ğ‘’ğ‘(ğ·(ğ‘’)))
ğ‘£ ğ‘’ğ‘(ğ‘“ ğ‘‘) â‹… ğ‘£ ğ‘’ğ‘(ğ·(ğ‘’))
(2)
=
â€–ğ‘£ ğ‘’ğ‘(ğ‘“ ğ‘‘)â€–â€–ğ‘£ ğ‘’ğ‘(ğ·(ğ‘’))â€–
where ğ‘£ ğ‘’ğ‘(ğ‘“ ğ‘‘) and ğ‘£ ğ‘’ğ‘(ğ·(ğ‘’)) are the vector representations of ğ‘“ ğ‘‘ and ğ·(ğ‘’), respectively. â€œâ€–â€–â€ de-
notes the magnitude of the vectors and â€œâ‹…â€ denotes the dot product. To compute the similarity
between ğ‘“ ğ‘‘ and ğ·(ğ‘’), we convert the tokens into fixed-length vectors using different embedding
models, including text-embedding-ada-003 [39], All-mpnet-base-v2 [43], GraphCodeBERT [27],
CodeBERT [20], and RoBERTa [35]. We individually evaluate these models to determine which
improves the overall results of ContextCraft, as detailed in Section 3.5. The retrieved examples
are leveraged to generate context-rich prompts. To account for the limited context window size
of LLMs, we limit retrieved examples to the top ten based on similarity, as using more examples
increases prompt length. However, the setting is subject to the changes of employed LLMs.

2.3 Probabilistic Token Positioning (PTP)
Method names are concise, so only a subset of tokens from the functional description is used
in the method names. Consequently, it would be beneficial to know how likely a token in func-
tional descriptions may appear in the corresponding method names. Method names follow pat-
terns; therefore, the probability of a token appearing in a specific position (prefix, infix, or suffix)
varies. Consequently, we compute how likely a given token (from functional descriptions) would
appear in different positions of method names to model such position-specific probability. Details
of the process are presented in the following paragraphs.
We retrieve all texts from the given corpus of examples (i.e., pairs of <functional description,
method name>) and decompose them into token sequences. Functional descriptions are split by
whitespace or punctuation, and method names are split by camelCase or underscores based on
programming language.
For each unique token, we calculate its likelihood of appearing as a prefix, infix, or suffix in
the method name from the training dataset (detailed in Section 3.3). The probability is defined and
computed as follows:
â€¢ Prefix probability, noted as ğ‘ƒprefix(ğ‘¡), represents the likelihood of a given token ğ‘¡ (from a func-
tional description) appearing as the first token in the training datasetâ€™s method names and also
existing in their functional descriptions:
ğ‘ƒprefix(ğ‘¡) = Occurrences of ğ‘¡ as prefixes of names
Occurrences of ğ‘¡ in descriptions (3)
â€¢ Infix probability, noted as ğ‘ƒinfix(ğ‘¡), represents the likelihood of a given token ğ‘¡ appearing in
the middle part of the method names:
ğ‘ƒinfix(ğ‘¡) = Occurrences of ğ‘¡ in the middle of names
Occurrences of ğ‘¡ in descriptions (4)
â€¢ Suffix probability, noted as ğ‘ƒsuffix(ğ‘¡), represents the likelihood of a given token ğ‘¡ appearing as
the last token of the method names:
ğ‘ƒsuffix(ğ‘¡) = Occurrences of ğ‘¡ as suffixes of names
Occurrences of ğ‘¡ in descriptions (5)
With the preceding computation, we create a mapping of ğ‘€ âˆ¶ ğ‘¡ â†’< ğ‘ƒprefix(ğ‘¡), ğ‘ƒinfix(ğ‘¡), ğ‘ƒsuffix(ğ‘¡) >
that maps each unique token in functional descriptions into a sequence of probabilities. With the
mapping ğ‘€, we rank the unique tokens in the functional descriptions of the selected best examples.
The ranking is presented in Algorithm 1. This algorithm takes the ğ‘ğ‘’ğ‘ ğ‘¡ğ¸ğ‘¥ğ‘ğ‘šğ‘ğ‘™ğ‘’ğ‘  as input. On line 2,
it initializes the ğ‘ƒğ‘‡ ğ‘ƒ, which will be returned as the final output. The algorithm enumerates each ele-
ment in ğ‘ğ‘’ğ‘ ğ‘¡ğ¸ğ‘¥ğ‘ğ‘šğ‘ğ‘™ğ‘’ğ‘  with another procedure ğ‘…ğ‘ğ‘›ğ‘˜ğ‘–ğ‘›ğ‘”4ğ‘†ğ‘–ğ‘›ğ‘”ğ‘™ğ‘’ğ¸ğ‘¥ğ‘ğ‘šğ‘ğ‘™ğ‘’ (Lines 3â€“4). This procedure
initializes a sequence of variables (Lines 10â€“15) that should be returned. The algorithm retrieves
a list of unique tokens, ğ‘‘ğ‘’ğ‘ ğ‘ğ‘‡ ğ‘œğ‘˜ğ‘’ğ‘›ğ¿ğ‘–ğ‘ ğ‘¡, from the description in the given example on line 16. FOR
iteration on lines 17â€“31 is the major body of the algorithm, where each iteration handles a unique
token in ğ‘‘ğ‘’ğ‘ ğ‘ğ‘‡ ğ‘œğ‘˜ğ‘’ğ‘›ğ¿ğ‘–ğ‘ ğ‘¡. Line 18 calculates the prefix, infix and suffix probabilities of the ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘› from
the training dataset. Line 19 compares the prefix probability of the token, i.e., ğ‘ƒprefix(ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘›) against
ğ‘šğ‘ğ‘¥ğ‘ƒğ‘Ÿğ‘’ğ‘“ ğ‘–ğ‘¥ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ , to validate whether its prefix probability is greater than any of the enumer-
ated tokens. If yes, the algorithm temporarily marks it as the to-be-returned token by assigning it
to ğ‘šğ‘ğ‘¥ğ‘ƒğ‘Ÿğ‘’ğ‘“ ğ‘–ğ‘¥ğ‘ƒğ‘Ÿğ‘œğ‘ğ‘ğ‘ğ‘–ğ‘™ğ‘–ğ‘¡ğ‘¦ on line 20. It also records its prefix token by assigning it to the variable
ğ‘ƒğ‘Ÿğ‘’ğ‘“ ğ‘–ğ‘¥ on line 21. The IF statement on lines 23-26 validates whether the current ğ‘¡ğ‘œğ‘˜ğ‘’ğ‘› has the
maximal infix probability in the same way, whereas the validation of maximal suffix probability is
accomplished by the IF statement on lines 27-30. Finally, on line 32, the algorithm returns three
tokens (i.e., ğ‘ƒğ‘Ÿğ‘’ğ‘“ ğ‘–ğ‘¥, ğ¼ ğ‘›ğ‘“ ğ‘–ğ‘¥, and ğ‘†ğ‘¢ğ‘“ ğ‘“ ğ‘–ğ‘¥) with the greatest probability of appearing as the method
nameâ€™s prefix, infix, and suffix, respectively. It also returns the corresponding probability scores.
This output is appended to ğ‘ƒğ‘‡ ğ‘ƒ on line 5, and the resulting ğ‘ƒğ‘‡ ğ‘ƒ is returned as the final output
after all examples are enumerated by ğ‘…ğ‘ğ‘›ğ‘˜ğ‘–ğ‘›ğ‘”4ğ‘†ğ‘–ğ‘›ğ‘”ğ‘™ğ‘’ğ¸ğ‘¥ğ‘ğ‘šğ‘ğ‘™ğ‘’.
2.4 Pivot Word Identification (PWI)
While PTP identifies tokens for direct copying, some functional description words aid in name
generation without direct copying. We propose a dedicated process called pivot word identification
(PWI) to identify such valuable words. The rationale of PWI is that if a word (ğ‘¤ ) in the functional
description is semantically similar to words (ğ‘›ğ‘¤ ) in the corresponding method name but not an
exact copy, this word (i.e., ğ‘¤ ) could be employed by LLMs to generate the associated name tokens
(i.e., ğ‘›ğ‘¤ ).
Algorithm 2 outlines PWI, which takes best examples as input (i.e., parameter ğ‘ğ‘’ğ‘ ğ‘¡ğ¸ğ‘¥ğ‘ğ‘šğ‘ğ‘™ğ‘’ğ‘ )
and returns a list of pivot words (pair of method nameâ€™s token and descriptionâ€™s token with their
similarity score) for each example. First, it initializes the output parameter ğ‘ƒğ‘Š ğ¼ with an empty set
on line 2. The primary body of the algorithm is an iteration on each of the examples (i.e., the FOR
statement on lines 3-16). Each iteration retrieves the tokens in the functional description (Line 4)
and method name (Line 5). On line 6, initializes ğ‘ƒğ‘Š ğ¿ as a list of pivot words of an example. The
nested loop on lines 7 and 8 takes each token of the method name noted as ğ‘šğ‘¡ and of description
as ğ‘‘ğ‘¡ and ensure tokens are not the same on line 9. If they are not, the algorithm passes them to a
function ğ‘†ğ‘–ğ‘š on line 10. Using the embedding model, this function calculates the cosine similarity
between ğ‘šğ‘¡ and ğ‘‘ğ‘¡ and stores the result in the variable ğ‘ ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ‘–ğ‘¡ğ‘¦ . On line 12, It appends ğ‘šğ‘¡ , ğ‘‘ğ‘¡ and
ğ‘ ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ‘–ğ‘¡ğ‘¦ into the list ğ‘ƒğ‘Š ğ¿ if they have a ğ‘ ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ‘–ğ‘¡ğ‘¦ score greater than or equal to ğ‘¡â„ğ‘Ÿğ‘’ğ‘ â„ğ‘œğ‘™ğ‘‘. We
set a threshold of 0.5 for semantic similarity to achieve a balance between precision and recall,
ensuring that only moderately similar token pairs are identified while minimizing noise. Once all
pivot words of an example are appended into ğ‘ƒğ‘Š ğ¿, it appends the ğ‘’ğ‘¥ğ‘ğ‘šğ‘ğ‘™ğ‘’ and corresponding
ğ‘ƒğ‘Š ğ¿ into ğ‘ƒğ‘Š ğ¼ on line 17 and returns this ğ‘ƒğ‘Š ğ¼ on line 19. On line 10, the algorithm employs
ğ‘ ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ‘–ğ‘¡ğ‘¦ = Sim(ğ‘šğ‘¡ , ğ‘‘ğ‘¡ ) to calculate the cosine similarity between two tokens ğ‘šğ‘¡ and ğ‘‘ğ‘¡ . We convert
the tokens into fixed-length vectors using a text embedding model (i.e.,text-embedding-ada-003,
OpenAIâ€™s next-generation embedding model at the time of selection [39]) to compute the similarity.
With the resulting embedding, we measure the similarity between ğ‘šğ‘¡ and ğ‘‘ğ‘¡ by computing the
cosine similarity between their corresponding vectors. To demonstrate the application of the PWI,
there are awesome examples:
â€¢ Example 1: <Functional description: â€œPersist the userâ€™s configuration preferences to ensure
changes are not lost.â€, Method name:â€œsaveSettingsâ€>
â€¢ Example 2: <Functional description: â€œVerify if the current user has the authority to access the
requested resource.â€, Method name: â€œcheckAccessâ€ >
â€¢ Example 3: <Functional description: â€œCreate a copy of this object.â€, Method name: â€œcloneâ€ >
For the first example, the semantic similarities between functional descriptions and method names
reveal notable correlations: the word â€œsaveâ€ from the method name â€œsaveSettingsâ€ achieves a sim-
ilarity score of 0.564 with â€œPersistâ€ from the description as both terms imply the action of data
maintaining or conserving. Additionally, â€œsettingsâ€ matches with â€œpreferencesâ€ with a similarity
score of 0.590, suggesting a strong relation since both terms refer to user-configurable parameters.
For the second example, the semantic analysis between the functional description and method
name vividly illustrates the contextual alignment of the terms used: â€œcheckâ€ from the method
name â€œcheckAccessâ€ shows a significant semantic correspondence with â€œverifyâ€ from the descrip-
tion, achieving a similarity score of 0.623, as both terms are commonly employed to confirm or
ascertain validity. Furthermore, the word â€œaccessâ€ is identically used in both contexts with a simi-
larity score of 0.580. Notably, the similarity between two occurrences of â€œaccessâ€ is not one because
they have different contexts and thus have different representing vectors.
For the third example, the semantic similarity analysis reveals a notable connection: â€œcloneâ€ in
the method name corresponds with â€œobjectâ€ from the functional description with a similarity score
of 0.618. This is logical because â€œcloneâ€ in source code usually refers to the action of creating an
exact copy of an â€œobjectâ€. This example highlights how semantic similarity analysis can effectively
establish a connection between a methodâ€™s action and its target, even when the direct linguistic
connection seems obscure (i.e., the two words are not lexically similar).
2.5 LLM-Based Feedback Mechanism (LFM)
PTP and PWI focus on token identification, while LFM offers quantitative feedback by evaluating
LLM performance with the best examples. Unlike token-based processing, the LFM proposed in
this section tries to help by evaluating the to-be-employed LLM (i.e., ChatGPT-4o as it presents the
OpenAIâ€™s latest LLM [38]) with the retrieved best examples and providing quantitative feedback
on the evaluation. For each example, this process works as follows:
â€¢ It feeds the LLM a prompt with a functional description from the example and asks it to
generate a method name according to the functional description.
â€¢ The LFM compares the name generated by the LLM and the ground truth, i.e., the method
name in the example. This comparison is based on character-level analysis, calculating the
edit distance between the generated and the original method name.
â€¢ It generates message ğ‘šğ‘ ğ‘” specifying how the generated names differ from the ground truth.
We take the following example to illustrate the process:
Example: <Function description: â€œcasts this class object to represent a subclass of the class repre-
sented by the specified object.â€, Method name: â€œasSubclassâ€ >. In this example, it requests the model
to generate a method name with the following prompt:
â€œSuggest a Java method name according to the given functional description: casts this
class object to represent a subclass of the class represented by the specified object.â€
The model generates a method name â€œcastToSubclassâ€. By comparing it against the ground truth
(i.e., â€œasSubclassâ€), our approach calculates the edit distance score as 4, indicating that there are
4 single-character edits required to transform â€œcastToSubclassâ€ into â€œasSubclassâ€. Consequently, it
generates the following messages as feedback:
â€œThe predicted method name by base LLM:â€˜castToSubclassâ€™ which has an edit distance
score: 04 as compared to the actual method name: â€˜asSubclassâ€™â€
The LFM provides feedback on all retrieved top examples, which is then used in the next process.
2.6 Template-Based Prompt Generation
With the outputs from processes introduced in the preceding sections, we gathered all the infor-
mation to create a context-rich prompt. The prompt is composed of five parts:
â€¢ Best examples retrieved from the corpus (copied from Section 2.1);
The preceding sections generated the best examples, probabilistic token positioning, pivot words,
and LLM-based feedback. Together, PTP and PWI offer a balanced prompt where PTP handles
token positioning and syntactic structure, and PWI ensures semantic relevance, improving overall
flexibility and effectiveness in method name generation. Additionally, the LFM integrated into the
prompt addresses inherent divergence in LLM behavior, ensuring that generated method names are
both relevant and contextually aligned with input descriptions. The query comprises a predefined
text (i.e., a command to the LLM) and the input of the proposed approach (i.e., the functional
description). An example of a generated prompt by ContextCraft is presented in Figure 2.
2.7 LLM-Based Method Name Suggestion
The automatically generated query is fed into an LLM to generate the method name. In the default
setting, we employ ChatGPT-4o as the LLM because it presents the state of the art at the time of
selection. However, as validated in Section 3.7, the proposed approach works well with various
LLMs, e.g., Gemini-1.5 and Llama-3.